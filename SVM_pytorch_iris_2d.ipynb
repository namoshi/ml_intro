{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMT3yPGrqKrrSEJr5RUHWm4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namoshi/ml_intro/blob/master/SVM_pytorch_iris_2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "18QtkVH7H_ny"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "from matplotlib.colors import ListedColormap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = np.loadtxt(\"iris.dat\",comments='#')\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:100,:2]\n",
        "y = iris.target[:100]\n",
        "target_names = iris.target_names\n",
        "\n",
        "print('Size of the data = ', X.shape)\n",
        "\n",
        "n = X.shape[0]\n",
        "mdim = X.shape[1]\n",
        "\n",
        "print('N=', n, 'mdim=', mdim)\n",
        "\n",
        "print('size of y', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4noB6a2oIc9o",
        "outputId": "e9eb9784-82b1-4576-f68f-e0da7d40665a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the data =  (100, 2)\n",
            "N= 100 mdim= 2\n",
            "size of y (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y)):\n",
        "    if y[i] == 0: y[i] = 1\n",
        "    else: y[i] = -1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "DVsWlp0l6xfe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class SVM(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SVM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Expect input to be shape (N, self.input_dim)\n",
        "        output = self.linear(input) # Shape (N, 1)\n",
        "        output = output.flatten() # Shape (N)\n",
        "        return output\n",
        "\n",
        "def HingeLoss(pred, truth):\n",
        "    # Expect both of shape (N)\n",
        "    loss_tensor = nn.ReLU()(1-pred*truth)\n",
        "    return torch.mean(loss_tensor)"
      ],
      "metadata": {
        "id": "MFbIKDgSIlWi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "\n"
      ],
      "metadata": {
        "id": "0DUnOtADIod3"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}