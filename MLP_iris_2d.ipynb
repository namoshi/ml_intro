{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/namoshi/ml_intro/blob/master/logit_iris_2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMtWL_fOIwqU"
   },
   "source": [
    "## 多層パーセプトロン\n",
    "多層パーセプトロンによるアヤメのデータ（２次元）の識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXi7NxVkIwqW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "hSSLOQv9Iwqb",
    "outputId": "09417da9-7dba-4ded-c0c8-1991c6c5ff78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data =  (150, 2)\n",
      "N= 150 mdim= 2\n",
      "size of y (150,)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# data = np.loadtxt(\"iris.dat\",comments='#')\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "print('Size of the data = ', X.shape)\n",
    "n = X.shape[0]\n",
    "mdim = X.shape[1]\n",
    "print('N=', n, 'mdim=', mdim)\n",
    "print('size of y', y.shape)\n",
    "\n",
    "# One hot encoding\n",
    "n_labels = len(np.unique(y))\n",
    "y = np.eye(n_labels)[y]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mc8c1-PoKi1p"
   },
   "source": [
    "多層パーセプトロンの学習（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bVZgssYZJ63M",
    "outputId": "22f606fe-23f4-42dc-90ac-2c443b34dfb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.0000\n",
      "Estimated Classes\n",
      " [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Estimated Probability\n",
      " [[0.37298474 0.4135144  0.32652407]\n",
      " [0.37068844 0.41454886 0.32636884]\n",
      " [0.37110954 0.41574489 0.32391029]\n",
      " [0.37047928 0.41632401 0.32329109]\n",
      " [0.37321422 0.41409915 0.32536224]\n",
      " [0.37478464 0.41199123 0.32778745]\n",
      " [0.37171701 0.41637226 0.32234213]\n",
      " [0.37245221 0.41405207 0.32597513]\n",
      " [0.36913097 0.41751846 0.32199979]\n",
      " [0.37109489 0.41456429 0.32604569]\n",
      " [0.37408513 0.41193216 0.32837309]\n",
      " [0.37210937 0.41519694 0.32419983]\n",
      " [0.37049108 0.41512843 0.32547166]\n",
      " [0.36930269 0.41814599 0.32067143]\n",
      " [0.37542283 0.40995047 0.3305046 ]\n",
      " [0.37664335 0.41059734 0.32868368]\n",
      " [0.37478464 0.41199123 0.32778745]\n",
      " [0.37298474 0.4135144  0.32652407]\n",
      " [0.37469498 0.41039527 0.33035569]\n",
      " [0.3740933  0.41359357 0.32562305]\n",
      " [0.37300243 0.41185422 0.32928064]\n",
      " [0.37372835 0.41356566 0.32591957]\n",
      " [0.37251846 0.41641324 0.32172759]\n",
      " [0.3722229  0.41346935 0.32714366]\n",
      " [0.37210937 0.41519694 0.32419983]\n",
      " [0.37087336 0.41397728 0.32724515]\n",
      " [0.37245221 0.41405207 0.32597513]\n",
      " [0.37312293 0.41296158 0.32736099]\n",
      " [0.37274882 0.41293779 0.32766846]\n",
      " [0.37110954 0.41574489 0.32391029]\n",
      " [0.37090257 0.41514298 0.32514835]\n",
      " [0.37300243 0.41185422 0.32928064]\n",
      " [0.37527246 0.41313561 0.3255967 ]\n",
      " [0.3758794  0.41156122 0.32771997]\n",
      " [0.37109489 0.41456429 0.32604569]\n",
      " [0.37167187 0.4140114  0.32660288]\n",
      " [0.37347523 0.41134878 0.32975092]\n",
      " [0.37305828 0.41466651 0.32448422]\n",
      " [0.36956866 0.41752654 0.32167336]\n",
      " [0.37260609 0.4134911  0.32683199]\n",
      " [0.37283552 0.41407481 0.32566681]\n",
      " [0.36669952 0.41688961 0.3250076 ]\n",
      " [0.37042982 0.41754843 0.32103069]\n",
      " [0.37283552 0.41407481 0.32566681]\n",
      " [0.3740933  0.41359357 0.32562305]\n",
      " [0.37049108 0.41512843 0.32547166]\n",
      " [0.3740933  0.41359357 0.32562305]\n",
      " [0.37089657 0.4163383  0.32297121]\n",
      " [0.37397637 0.41246919 0.32757527]\n",
      " [0.37206432 0.41403092 0.32628717]\n",
      " [0.37321077 0.40424092 0.3400475 ]\n",
      " [0.3730652  0.40685032 0.33678303]\n",
      " [0.37287663 0.40463662 0.33984976]\n",
      " [0.36885776 0.4111484  0.33365976]\n",
      " [0.37173469 0.4063183  0.33862883]\n",
      " [0.37110096 0.4101645  0.33345467]\n",
      " [0.37335884 0.40733425 0.33587213]\n",
      " [0.36815634 0.41449281 0.32837819]\n",
      " [0.37212568 0.4058904  0.3388744 ]\n",
      " [0.37000523 0.41281499 0.32992325]\n",
      " [0.36661964 0.41390984 0.33065329]\n",
      " [0.37204533 0.40919162 0.33421378]\n",
      " [0.36911646 0.40858645 0.33755605]\n",
      " [0.37184411 0.40819611 0.33586665]\n",
      " [0.37136609 0.41069745 0.33239474]\n",
      " [0.37283363 0.40549102 0.33879744]\n",
      " [0.37174469 0.41071537 0.33207095]\n",
      " [0.37083064 0.40964033 0.33449721]\n",
      " [0.36931969 0.40762229 0.33883986]\n",
      " [0.36980987 0.41064056 0.33372492]\n",
      " [0.37276551 0.40923308 0.33358145]\n",
      " [0.37148138 0.40817842 0.33619058]\n",
      " [0.37053285 0.4071868  0.33843443]\n",
      " [0.37148138 0.40817842 0.33619058]\n",
      " [0.37203385 0.40678954 0.33772465]\n",
      " [0.37246667 0.40590934 0.33855848]\n",
      " [0.37185439 0.40500402 0.34027396]\n",
      " [0.37249987 0.40547108 0.33910856]\n",
      " [0.37176565 0.40868057 0.33521054]\n",
      " [0.37033134 0.41013522 0.33411871]\n",
      " [0.36926547 0.4111567  0.33331531]\n",
      " [0.36926547 0.4111567  0.33331531]\n",
      " [0.37083064 0.40964033 0.33449721]\n",
      " [0.37102848 0.40864683 0.33586353]\n",
      " [0.37149689 0.41177081 0.33054367]\n",
      " [0.37353632 0.40878798 0.33364336]\n",
      " [0.37283363 0.40549102 0.33879744]\n",
      " [0.36978726 0.40716255 0.33911081]\n",
      " [0.37174469 0.41071537 0.33207095]\n",
      " [0.36966918 0.41116658 0.33297397]\n",
      " [0.37006883 0.41117803 0.33263585]\n",
      " [0.37220278 0.4082151  0.33554641]\n",
      " [0.37044796 0.40962605 0.33483035]\n",
      " [0.36793975 0.41391144 0.32959935]\n",
      " [0.37059624 0.41066602 0.33305298]\n",
      " [0.37185399 0.41019956 0.33280475]\n",
      " [0.37147957 0.41018132 0.33312791]\n",
      " [0.37191474 0.40771948 0.33650417]\n",
      " [0.36899692 0.4133538  0.32976519]\n",
      " [0.37110096 0.4101645  0.33345467]\n",
      " [0.37335884 0.40733425 0.33587213]\n",
      " [0.37083064 0.40964033 0.33449721]\n",
      " [0.37257761 0.40379256 0.34114528]\n",
      " [0.37197787 0.40725064 0.33712341]\n",
      " [0.37242737 0.40635517 0.33799137]\n",
      " [0.37257148 0.4018574  0.34334854]\n",
      " [0.36858924 0.41449771 0.32803533]\n",
      " [0.37226788 0.40297948 0.34237953]\n",
      " [0.3707727  0.40538822 0.34072123]\n",
      " [0.37443738 0.40351913 0.339839  ]\n",
      " [0.37310409 0.40639669 0.33736931]\n",
      " [0.37132632 0.40675503 0.33837131]\n",
      " [0.37252727 0.40504032 0.33964194]\n",
      " [0.36994044 0.41012279 0.33445581]\n",
      " [0.37120925 0.40965603 0.33416754]\n",
      " [0.3730652  0.40685032 0.33678303]\n",
      " [0.37242737 0.40635517 0.33799137]\n",
      " [0.37489141 0.40165482 0.34145357]\n",
      " [0.37130225 0.40143033 0.34499279]\n",
      " [0.36911646 0.40858645 0.33755605]\n",
      " [0.37320016 0.40465726 0.33954454]\n",
      " [0.37098326 0.410681   0.33272211]\n",
      " [0.37193795 0.4014591  0.34436192]\n",
      " [0.3712632  0.4072162  0.33777173]\n",
      " [0.3734892  0.40553419 0.33818708]\n",
      " [0.37321788 0.40343005 0.34100673]\n",
      " [0.37155574 0.40770169 0.33682732]\n",
      " [0.37220278 0.4082151  0.33554641]\n",
      " [0.37168205 0.40677168 0.33804613]\n",
      " [0.37258469 0.40339126 0.34161525]\n",
      " [0.37194875 0.40257629 0.34313121]\n",
      " [0.37481754 0.40093697 0.34222723]\n",
      " [0.37168205 0.40677168 0.33804613]\n",
      " [0.37162252 0.40723279 0.33744573]\n",
      " [0.37074389 0.40814699 0.33684925]\n",
      " [0.37255898 0.40149141 0.34374694]\n",
      " [0.37369382 0.40735815 0.33556908]\n",
      " [0.37272546 0.40682887 0.33709304]\n",
      " [0.37212811 0.40869945 0.33488952]\n",
      " [0.37287663 0.40463662 0.33984976]\n",
      " [0.37283363 0.40549102 0.33879744]\n",
      " [0.37287663 0.40463662 0.33984976]\n",
      " [0.37083064 0.40964033 0.33449721]\n",
      " [0.37318447 0.40508096 0.33902557]\n",
      " [0.3734892  0.40553419 0.33818708]\n",
      " [0.37249987 0.40547108 0.33910856]\n",
      " [0.37053285 0.4071868  0.33843443]\n",
      " [0.37242737 0.40635517 0.33799137]\n",
      " [0.37364849 0.40782716 0.33494543]\n",
      " [0.37204533 0.40919162 0.33421378]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurita/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_LR = MLPClassifier(hidden_layer_sizes=6,  activation=\"logistic\", solver=\"sgd\")\n",
    "clf_LR.fit(X, y)\n",
    "\n",
    "print(\"Mean Accuracy: %.4f\" % clf_LR.score(X, y))\n",
    "\n",
    "yy = clf_LR.predict(X)\n",
    "pp = clf_LR.predict_proba(X)\n",
    "print('Estimated Classes\\n', yy)\n",
    "print('Estimated Probability\\n', pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXJ--wVRIwq8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "logit_iris_2d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
